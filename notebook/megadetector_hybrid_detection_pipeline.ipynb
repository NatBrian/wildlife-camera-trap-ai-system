{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro_md",
   "metadata": {},
   "source": [
    "# Hybrid Detection Model: MegaDetector + Species Classification\n",
    "\n",
    "This notebook fine-tunes the **MDV6-yolov10-c** checkpoint to create a hybrid detection model with **7 classes**:\n",
    "\n",
    "| Class ID | Label | Description |\n",
    "|----------|-------|-------------|\n",
    "| 0 | animal | Generic animal (from MDV6 base) |\n",
    "| 1 | person | Human detection (from MDV6 base) |\n",
    "| 2 | vehicle | Vehicle detection (from MDV6 base) |\n",
    "| 3 | bird | Species-specific (Open Images) |\n",
    "| 4 | squirrel | Species-specific (Open Images) |\n",
    "| 5 | dog | Species-specific (Open Images) |\n",
    "| 6 | cat | Species-specific (Open Images) |\n",
    "\n",
    "**Strategy**: The pretrained MDV6 checkpoint already detects `animal`, `person`, and `vehicle`. We fine-tune with frozen backbone layers to:\n",
    "- **Preserve** generic detection for unseen animals, people, and vehicles\n",
    "- **Add** species-specific detection for bird, squirrel, dog, cat\n",
    "\n",
    "**What this notebook does**:\n",
    "- Download Open Images data for the 4 species (bird, squirrel, dog, cat)\n",
    "- Convert to YOLO format with correct class IDs (3, 4, 5, 6)\n",
    "- Fine-tune MDV6 with frozen backbone to prevent catastrophic forgetting\n",
    "- Evaluate hybrid detection on test images\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup_md",
   "metadata": {},
   "source": [
    "## 1) Setup: Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cfcc22",
   "metadata": {
    "id": "15cfcc22"
   },
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "# If running in Colab, keep `--upgrade` flags; in local environment, you may want to control versions.\n",
    "!pip install -U ultralytics fiftyone fiftyone-brain fiftyone-db tqdm\n",
    "\n",
    "# Optional: roboflow or fiftyone may help for visualisation and dataset downloads\n",
    "# !pip install roboflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1ecce0",
   "metadata": {
    "id": "1e1ecce0"
   },
   "outputs": [],
   "source": [
    "# Uninstall current installations to avoid conflicts\n",
    "!pip uninstall -y ultralytics torch torchvision torchaudio\n",
    "\n",
    "# Install PyTorch with CUDA 12.6 (ensure this matches your Colab GPU's CUDA version)\n",
    "# The previous output showed torch-2.9.0+cu126, so targeting CUDA 12.6\n",
    "!pip install torch==2.9.0+cu126 torchvision==0.24.0+cu126 torchaudio==2.9.0 --index-url https://download.pytorch.org/whl/cu126\n",
    "\n",
    "# Reinstall ultralytics\n",
    "!pip install -U ultralytics\n",
    "\n",
    "# Verify GPU availability after reinstallation\n",
    "import torch\n",
    "print(f\"torch.cuda.is_available(): {torch.cuda.is_available()}\")\n",
    "print(f\"torch.cuda.device_count(): {torch.cuda.device_count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classes_md",
   "metadata": {},
   "source": [
    "## 2) Define 7-class structure and create `data.yaml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data_yaml_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the 7-class structure for hybrid detection\n",
    "# Classes 0-2 are preserved from MDV6 base model\n",
    "# Classes 3-6 are species-specific from Open Images fine-tuning\n",
    "import yaml, os\n",
    "\n",
    "# IMPORTANT: Class order must match MDV6 base (0=animal, 1=person, 2=vehicle)\n",
    "classes = [\"animal\", \"person\", \"vehicle\", \"bird\", \"squirrel\", \"dog\", \"cat\"]\n",
    "\n",
    "data_yaml = {\n",
    "    'train': 'datasets/hybrid/images/train',\n",
    "    'val': 'datasets/hybrid/images/val',\n",
    "    'test': 'datasets/hybrid/images/test',\n",
    "    'nc': len(classes),\n",
    "    'names': classes\n",
    "}\n",
    "\n",
    "os.makedirs('datasets/hybrid', exist_ok=True)\n",
    "with open('datasets/hybrid/data.yaml','w') as f:\n",
    "    yaml.dump(data_yaml, f)\n",
    "\n",
    "print('Created datasets/hybrid/data.yaml with 7 classes:')\n",
    "for i, cls in enumerate(classes):\n",
    "    source = 'MDV6 base' if i < 3 else 'Open Images'\n",
    "    print(f'  {i}: {cls} ({source})')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "download_md",
   "metadata": {},
   "source": [
    "## 3) Download Open Images for the 4 Species\n",
    "\n",
    "We **only download data for the 4 species** (bird, squirrel, dog, cat).\n",
    "\n",
    "**Why not download animal/person/vehicle?**\n",
    "- The MDV6 checkpoint already has strong features for these generic classes\n",
    "- We use `freeze=10` during training to preserve the backbone\n",
    "- This prevents catastrophic forgetting of the base detection capabilities\n",
    "\n",
    "The fine-tuning teaches the model to:\n",
    "1. Recognize the 4 specific species (bird, squirrel, dog, cat)\n",
    "2. Keep detecting generic animals, people, and vehicles from the frozen backbone\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "download_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Open Images for the 4 species only\n",
    "# We DO NOT need to retrain on animal/person/vehicle - MDV6 base handles those\n",
    "from fiftyone import zoo as foz\n",
    "import fiftyone as fo\n",
    "import os\n",
    "\n",
    "# Only the 4 species we want to add to MDV6's detection\n",
    "species_classes = [\"bird\", \"squirrel\", \"dog\", \"cat\"]\n",
    "\n",
    "# Map to Open Images label strings (case-sensitive)\n",
    "oi_class_map = {\n",
    "    \"bird\": \"Bird\",\n",
    "    \"squirrel\": \"Squirrel\",\n",
    "    \"dog\": \"Dog\",\n",
    "    \"cat\": \"Cat\"\n",
    "}\n",
    "\n",
    "# YOLO class IDs for the species (classes 3-6 in our 7-class system)\n",
    "species_class_ids = {\n",
    "    \"bird\": 3,\n",
    "    \"squirrel\": 4,\n",
    "    \"dog\": 5,\n",
    "    \"cat\": 6\n",
    "}\n",
    "\n",
    "max_samples_per_class = 1000\n",
    "\n",
    "os.makedirs('datasets/hybrid/images', exist_ok=True)\n",
    "os.makedirs('datasets/hybrid/labels', exist_ok=True)\n",
    "\n",
    "for cls in species_classes:\n",
    "    oi_label = oi_class_map[cls]\n",
    "    yolo_id = species_class_ids[cls]\n",
    "    print(f\"Downloading {max_samples_per_class} samples for '{oi_label}' \u2192 class {yolo_id} ({cls})...\")\n",
    "    try:\n",
    "        dataset = foz.load_zoo_dataset(\n",
    "            \"open-images-v7\",\n",
    "            split=\"train\",\n",
    "            label_types=[\"detections\"],\n",
    "            classes=[oi_label],\n",
    "            max_samples=max_samples_per_class,\n",
    "            dataset_name=f\"oi_species_{cls}\",\n",
    "            seed=51,\n",
    "            download=True\n",
    "        )\n",
    "        print(f\"  \u2713 Downloaded {len(dataset)} samples for {cls}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  \u2717 Error downloading {cls}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convert_md",
   "metadata": {},
   "source": [
    "### Convert to YOLO format with correct class IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convert_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Open Images to YOLO format with CORRECT class IDs (3-6)\n",
    "import glob, shutil, os\n",
    "import fiftyone as fo\n",
    "from fiftyone.utils.yolo import YOLOv5DatasetExporter\n",
    "\n",
    "# Load the data.yaml we created earlier\n",
    "with open('datasets/hybrid/data.yaml', 'r') as f:\n",
    "    import yaml\n",
    "    data_config = yaml.safe_load(f)\n",
    "\n",
    "# Mapping from Open Images labels \u2192 our YOLO class IDs\n",
    "# CRITICAL: Species get IDs 3-6, NOT 0-3\n",
    "oi_to_yolo_id = {\n",
    "    \"Bird\": 3,      # bird\n",
    "    \"Squirrel\": 4,  # squirrel\n",
    "    \"Dog\": 5,       # dog\n",
    "    \"Cat\": 6        # cat\n",
    "}\n",
    "\n",
    "# Process each downloaded dataset\n",
    "for ds_name in fo.list_datasets():\n",
    "    if not ds_name.startswith('oi_species_'):\n",
    "        continue\n",
    "    \n",
    "    print(f\"Processing {ds_name}...\")\n",
    "    dataset = fo.load_dataset(ds_name)\n",
    "    \n",
    "    # Remap labels to our class names\n",
    "    for sample in dataset.iter_samples(autosave=True):\n",
    "        if sample.ground_truth is None:\n",
    "            continue\n",
    "        \n",
    "        filtered_detections = []\n",
    "        for det in sample.ground_truth.detections:\n",
    "            if det.label in oi_to_yolo_id:\n",
    "                # Map to our YOLO class name\n",
    "                mapped_label = data_config['names'][oi_to_yolo_id[det.label]]\n",
    "                det.label = mapped_label\n",
    "                filtered_detections.append(det)\n",
    "        sample.ground_truth.detections = filtered_detections\n",
    "    \n",
    "    # Set default classes to our 7-class list\n",
    "    dataset.default_classes = data_config['names']\n",
    "    \n",
    "    # Export to YOLO format\n",
    "    export_dir = f\"export_{ds_name}\"\n",
    "    if os.path.exists(export_dir):\n",
    "        shutil.rmtree(export_dir)\n",
    "    \n",
    "    exporter = YOLOv5DatasetExporter(\n",
    "        export_dir=export_dir,\n",
    "        classes=data_config['names'],  # Use our 7-class list\n",
    "        export_media=True\n",
    "    )\n",
    "    dataset.export(dataset_exporter=exporter, label_field=\"ground_truth\")\n",
    "    \n",
    "    # Move files to main dataset folder\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        imgs_src = os.path.join(export_dir, 'images', split)\n",
    "        lbls_src = os.path.join(export_dir, 'labels', split)\n",
    "        \n",
    "        if os.path.exists(imgs_src):\n",
    "            for f in glob.glob(imgs_src + '/*'):\n",
    "                shutil.copy(f, 'datasets/hybrid/images/')\n",
    "        if os.path.exists(lbls_src):\n",
    "            for f in glob.glob(lbls_src + '/*'):\n",
    "                shutil.copy(f, 'datasets/hybrid/labels/')\n",
    "    \n",
    "    shutil.rmtree(export_dir)\n",
    "    print(f\"  \u2713 Exported {ds_name}\")\n",
    "\n",
    "print(\"\\n\u2713 Export complete. Verifying class IDs in labels...\")\n",
    "\n",
    "# Verify class IDs are correct (should be 3-6 only for species data)\n",
    "from collections import Counter\n",
    "class_counts = Counter()\n",
    "for label_file in glob.glob('datasets/hybrid/labels/*.txt'):\n",
    "    with open(label_file, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if parts:\n",
    "                class_id = int(parts[0])\n",
    "                class_counts[class_id] += 1\n",
    "\n",
    "print(\"\\nClass distribution in labels:\")\n",
    "for cls_id in sorted(class_counts.keys()):\n",
    "    cls_name = data_config['names'][cls_id] if cls_id < len(data_config['names']) else 'UNKNOWN'\n",
    "    print(f\"  {cls_id}: {cls_name} = {class_counts[cls_id]} boxes\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pseudo_md",
   "metadata": {},
   "source": [
    "## 4) Optional: Pseudo-label Backyard Images with MDV6\n",
    "\n",
    "If you have unlabeled backyard images, use MDV6 to generate pseudo-labels.\n",
    "\n",
    "**Class ID mapping from MDV6**:\n",
    "- MDV6 class 0 (animal) \u2192 Our class 0 (animal) - generic detection\n",
    "- MDV6 class 1 (person) \u2192 Our class 1 (person)\n",
    "- MDV6 class 2 (vehicle) \u2192 Our class 2 (vehicle)\n",
    "\n",
    "This adds training data for the generic classes to reinforce MDV6's existing capabilities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pseudo_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pseudo-labeling with MDV6 for generic classes (animal, person, vehicle)\n",
    "from ultralytics import YOLO\n",
    "import shutil, cv2, os\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "mdv6_checkpoint = \"MDV6-yolov10-c.pt\"\n",
    "images_to_label_dir = Path(\"datasets/hybrid/images_to_label\")\n",
    "output_images_dir = Path(\"datasets/hybrid/images\")\n",
    "output_labels_dir = Path(\"datasets/hybrid/labels\")\n",
    "\n",
    "# Create directories\n",
    "images_to_label_dir.mkdir(parents=True, exist_ok=True)\n",
    "output_images_dir.mkdir(parents=True, exist_ok=True)\n",
    "output_labels_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "images_to_label = list(images_to_label_dir.glob(\"*.*\"))\n",
    "print(f\"Found {len(images_to_label)} images to pseudo-label\")\n",
    "print(\"(Place unlabeled images in datasets/hybrid/images_to_label/)\")\n",
    "\n",
    "if len(images_to_label) > 0:\n",
    "    # Download checkpoint if needed\n",
    "    if not os.path.exists(mdv6_checkpoint):\n",
    "        print(f\"Downloading {mdv6_checkpoint}...\")\n",
    "        !wget -q https://zenodo.org/records/15398270/files/MDV6-yolov10-c.pt?download=1 -O {mdv6_checkpoint}\n",
    "    \n",
    "    model = YOLO(mdv6_checkpoint)\n",
    "    \n",
    "    # MDV6 classes: 0=animal, 1=person, 2=vehicle\n",
    "    # These map DIRECTLY to our classes 0, 1, 2\n",
    "    for img_path in tqdm(images_to_label, desc=\"Pseudo-labeling\"):\n",
    "        result = model.predict(str(img_path), conf=0.3, imgsz=1280, verbose=False)[0]\n",
    "        \n",
    "        # Get image dimensions\n",
    "        img = cv2.imread(str(img_path))\n",
    "        if img is None:\n",
    "            continue\n",
    "        h, w = img.shape[:2]\n",
    "        \n",
    "        # Copy image\n",
    "        shutil.copy(img_path, output_images_dir / img_path.name)\n",
    "        \n",
    "        # Generate label file\n",
    "        label_path = output_labels_dir / (img_path.stem + \".txt\")\n",
    "        with open(label_path, 'w') as f:\n",
    "            if result.boxes is not None and len(result.boxes) > 0:\n",
    "                for box in result.boxes:\n",
    "                    # Get box coordinates (xyxy format)\n",
    "                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "                    cls_id = int(box.cls[0].cpu().numpy())\n",
    "                    \n",
    "                    # Only keep MDV6 classes 0, 1, 2 (animal, person, vehicle)\n",
    "                    if cls_id > 2:\n",
    "                        continue\n",
    "                    \n",
    "                    # Convert to YOLO format (normalized cx, cy, w, h)\n",
    "                    cx = ((x1 + x2) / 2) / w\n",
    "                    cy = ((y1 + y2) / 2) / h\n",
    "                    bw = (x2 - x1) / w\n",
    "                    bh = (y2 - y1) / h\n",
    "                    \n",
    "                    f.write(f\"{cls_id} {cx:.6f} {cy:.6f} {bw:.6f} {bh:.6f}\\n\")\n",
    "    \n",
    "    print(\"\u2713 Pseudo-labeling complete\")\n",
    "else:\n",
    "    print(\"No images to pseudo-label. Skipping.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "split_md",
   "metadata": {},
   "source": [
    "## 5) Create train/val/test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "split_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train/val/test splits\n",
    "import random, shutil, glob\n",
    "from pathlib import Path\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "images_dir = Path(\"datasets/hybrid/images\")\n",
    "labels_dir = Path(\"datasets/hybrid/labels\")\n",
    "\n",
    "# Find all image files with matching labels\n",
    "images = [p for p in images_dir.glob(\"*.*\") \n",
    "          if p.suffix.lower() in ['.jpg', '.jpeg', '.png'] and p.is_file()]\n",
    "\n",
    "pairs = []\n",
    "for img in images:\n",
    "    label = labels_dir / (img.stem + \".txt\")\n",
    "    if label.exists():\n",
    "        pairs.append((img, label))\n",
    "\n",
    "print(f\"Found {len(pairs)} image/label pairs\")\n",
    "\n",
    "# Shuffle and split (80/10/10)\n",
    "random.shuffle(pairs)\n",
    "n = len(pairs)\n",
    "train_n = int(n * 0.8)\n",
    "val_n = int(n * 0.1)\n",
    "\n",
    "train_pairs = pairs[:train_n]\n",
    "val_pairs = pairs[train_n:train_n + val_n]\n",
    "test_pairs = pairs[train_n + val_n:]\n",
    "\n",
    "print(f\"Split: train={len(train_pairs)}, val={len(val_pairs)}, test={len(test_pairs)}\")\n",
    "\n",
    "def move_pairs(pairs, split_name):\n",
    "    img_dir = Path(f\"datasets/hybrid/images/{split_name}\")\n",
    "    lbl_dir = Path(f\"datasets/hybrid/labels/{split_name}\")\n",
    "    img_dir.mkdir(parents=True, exist_ok=True)\n",
    "    lbl_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    for img, lbl in pairs:\n",
    "        shutil.move(str(img), img_dir / img.name)\n",
    "        shutil.move(str(lbl), lbl_dir / lbl.name)\n",
    "\n",
    "move_pairs(train_pairs, \"train\")\n",
    "move_pairs(val_pairs, \"val\")\n",
    "move_pairs(test_pairs, \"test\")\n",
    "\n",
    "print(\"\u2713 Created train/val/test splits\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "train_md",
   "metadata": {},
   "source": [
    "## 6) Training: Fine-tune MDV6 for Hybrid Detection\n",
    "\n",
    "**Key training parameters for preserving generic detection:**\n",
    "\n",
    "- `freeze=10`: Freeze backbone layers to preserve MDV6's learned features\n",
    "- `lr0=0.001`: Low learning rate to prevent overwriting base knowledge\n",
    "- `lrf=0.01`: Learning rate decay\n",
    "\n",
    "The frozen backbone retains the ability to detect generic animals, people, and vehicles,\n",
    "while the head learns to classify the 4 specific species.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune MDV6 for hybrid detection\n",
    "from ultralytics import YOLO\n",
    "import yaml\n",
    "import os\n",
    "\n",
    "# Paths\n",
    "mdv6_checkpoint = \"MDV6-yolov10-c.pt\"\n",
    "data_yaml_path = \"datasets/hybrid/data.yaml\"\n",
    "\n",
    "# Download checkpoint if needed\n",
    "if not os.path.exists(mdv6_checkpoint):\n",
    "    print(f\"Downloading {mdv6_checkpoint}...\")\n",
    "    !wget -q https://zenodo.org/records/15398270/files/MDV6-yolov10-c.pt?download=1 -O {mdv6_checkpoint}\n",
    "\n",
    "# Update data.yaml with absolute paths\n",
    "base_dir = os.path.abspath('datasets/hybrid')\n",
    "with open(data_yaml_path, 'r') as f:\n",
    "    data_config = yaml.safe_load(f)\n",
    "\n",
    "data_config['train'] = os.path.join(base_dir, 'images', 'train')\n",
    "data_config['val'] = os.path.join(base_dir, 'images', 'val')\n",
    "data_config['test'] = os.path.join(base_dir, 'images', 'test')\n",
    "\n",
    "with open(data_yaml_path, 'w') as f:\n",
    "    yaml.dump(data_config, f)\n",
    "\n",
    "print(\"Data config:\")\n",
    "print(yaml.dump(data_config))\n",
    "\n",
    "# Load MDV6 and fine-tune\n",
    "model = YOLO(mdv6_checkpoint)\n",
    "\n",
    "# Train with frozen backbone to preserve generic detection\n",
    "model.train(\n",
    "    data=data_yaml_path,\n",
    "    epochs=100,\n",
    "    imgsz=640,\n",
    "    batch=8,\n",
    "    device=0,\n",
    "    name=\"yolov10_hybrid_7class\",\n",
    "    freeze=10,      # CRITICAL: Freeze backbone to preserve MDV6 features\n",
    "    lr0=0.001,      # Low learning rate for fine-tuning\n",
    "    lrf=0.01,       # Final LR = lr0 * lrf\n",
    "    patience=20,    # Early stopping patience\n",
    "    save=True,\n",
    "    plots=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eval_md",
   "metadata": {},
   "source": [
    "## 7) Evaluate the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eval_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the trained hybrid model\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "\n",
    "# Path to trained model\n",
    "trained_model_path = \"runs/detect/yolov10_hybrid_7class/weights/best.pt\"\n",
    "\n",
    "if not os.path.exists(trained_model_path):\n",
    "    print(f\"Model not found at {trained_model_path}\")\n",
    "    print(\"Available runs:\")\n",
    "    for d in os.listdir(\"runs/detect\"):\n",
    "        print(f\"  - runs/detect/{d}\")\n",
    "else:\n",
    "    model = YOLO(trained_model_path)\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    print(\"\\nEvaluating on test set...\")\n",
    "    metrics = model.val(data=\"datasets/hybrid/data.yaml\", imgsz=640, batch=8)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"HYBRID DETECTION MODEL EVALUATION\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"mAP50: {metrics.box.map50:.4f}\")\n",
    "    print(f\"mAP50-95: {metrics.box.map:.4f}\")\n",
    "    print(\"\\nPer-class AP50:\")\n",
    "    class_names = [\"animal\", \"person\", \"vehicle\", \"bird\", \"squirrel\", \"dog\", \"cat\"]\n",
    "    for i, ap in enumerate(metrics.box.ap50):\n",
    "        source = \"(MDV6 base)\" if i < 3 else \"(Open Images)\"\n",
    "        print(f\"  {i}: {class_names[i]:10s} = {ap:.4f} {source}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inference_md",
   "metadata": {},
   "source": [
    "## 8) Run inference on test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inference_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference on test images\n",
    "from ultralytics import YOLO\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "trained_model_path = \"runs/detect/yolov10_hybrid_7class/weights/best.pt\"\n",
    "model = YOLO(trained_model_path)\n",
    "\n",
    "# Get test images\n",
    "test_images = glob.glob(\"datasets/hybrid/images/test/*.*\")[:8]\n",
    "print(f\"Running inference on {len(test_images)} test images...\")\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(\"datasets/hybrid/images/inference\", exist_ok=True)\n",
    "\n",
    "# Run inference\n",
    "for img_path in test_images:\n",
    "    results = model.predict(img_path, imgsz=640, conf=0.25, verbose=False)\n",
    "    \n",
    "    # Save annotated image\n",
    "    out_path = f\"datasets/hybrid/images/inference/{os.path.basename(img_path)}\"\n",
    "    results[0].save(out_path)\n",
    "    \n",
    "    # Print detections\n",
    "    print(f\"\\n{os.path.basename(img_path)}:\")\n",
    "    if results[0].boxes is not None:\n",
    "        for box in results[0].boxes:\n",
    "            cls_id = int(box.cls[0])\n",
    "            conf = float(box.conf[0])\n",
    "            cls_name = model.names[cls_id]\n",
    "            print(f\"  - {cls_name}: {conf:.2f}\")\n",
    "\n",
    "print(\"\\n\u2713 Inference complete. Results saved to datasets/hybrid/images/inference/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "export_md",
   "metadata": {},
   "source": [
    "## 9) Export to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "export_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to ONNX format\n",
    "from ultralytics import YOLO\n",
    "\n",
    "trained_model_path = \"runs/detect/yolov10_hybrid_7class/weights/best.pt\"\n",
    "model = YOLO(trained_model_path)\n",
    "\n",
    "# Export to ONNX\n",
    "model.export(format='onnx', imgsz=640, simplify=True)\n",
    "\n",
    "print(\"\\n\u2713 Exported to ONNX format\")\n",
    "print(\"Model file: runs/detect/yolov10_hybrid_7class/weights/best.onnx\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "notes_md",
   "metadata": {},
   "source": [
    "## Summary: Hybrid Detection Model\n",
    "\n",
    "The trained model can now:\n",
    "\n",
    "1. **Detect generic classes** (preserved from MDV6 base):\n",
    "   - `animal` (class 0): Any animal not specifically trained\n",
    "   - `person` (class 1): Human detection\n",
    "   - `vehicle` (class 2): Cars, trucks, etc.\n",
    "\n",
    "2. **Detect specific species** (from Open Images fine-tuning):\n",
    "   - `bird` (class 3)\n",
    "   - `squirrel` (class 4)\n",
    "   - `dog` (class 5)\n",
    "   - `cat` (class 6)\n",
    "\n",
    "**During inference:**\n",
    "- A deer \u2192 detected as `animal` (generic)\n",
    "- A squirrel \u2192 detected as `squirrel` (specific)\n",
    "- A human \u2192 detected as `person`\n",
    "- A car \u2192 detected as `vehicle`\n",
    "\n",
    "---\n",
    "\n",
    "**Files:**\n",
    "- Trained model: `runs/detect/yolov10_hybrid_7class/weights/best.pt`\n",
    "- ONNX export: `runs/detect/yolov10_hybrid_7class/weights/best.onnx`\n",
    "- Labels JSON: Create with `{\"0\": \"animal\", \"1\": \"person\", \"2\": \"vehicle\", \"3\": \"bird\", \"4\": \"squirrel\", \"5\": \"dog\", \"6\": \"cat\"}`\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}